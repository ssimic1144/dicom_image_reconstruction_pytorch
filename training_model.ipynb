{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from nn_model import Net\n",
    "from dicom_dataset import DicomDataset\n",
    "from ssim_loss import SSIM\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining training parametars\n",
    "image_size = 64\n",
    "batch_size = 60\n",
    "learning_rate = 0.001\n",
    "num_of_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing dataset\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])\n",
    "\n",
    "dataset = DicomDataset(\"../slike/\", transform=transformations)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "validation_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset)-train_size-validation_size\n",
    "\n",
    "train_set, validation_set, test_set = random_split(dataset, [train_size, validation_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set,batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
       "  (upsamp): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (relu): ReLU()\n",
       "  (conv64): Sequential(\n",
       "    (0): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (conv128): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (conv256): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (conv256x256): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (upsample1): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (mid_conv1): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (upsample2): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (mid_conv2): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (upsample3): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (mid_conv3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (end_layer): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (7): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating model\n",
    "model = Net()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing criterion and optimizer\n",
    "criterion_ssim = SSIM()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Completed: Train Avg. Loss: 0.9091\n",
      "Epoch 1 Validation Completed: Validation Avg. Loss: 0.6196\n",
      "This epoch took 9.74 seconds to complete\n",
      "Epoch 2 Training Completed: Train Avg. Loss: 0.3727\n",
      "Epoch 2 Validation Completed: Validation Avg. Loss: 0.2547\n",
      "This epoch took 9.57 seconds to complete\n",
      "Epoch 3 Training Completed: Train Avg. Loss: 0.2517\n",
      "Epoch 3 Validation Completed: Validation Avg. Loss: 0.2499\n",
      "This epoch took 9.57 seconds to complete\n",
      "Epoch 4 Training Completed: Train Avg. Loss: 0.2496\n",
      "Epoch 4 Validation Completed: Validation Avg. Loss: 0.2483\n",
      "This epoch took 9.54 seconds to complete\n",
      "Epoch 5 Training Completed: Train Avg. Loss: 0.2482\n",
      "Epoch 5 Validation Completed: Validation Avg. Loss: 0.2471\n",
      "This epoch took 9.75 seconds to complete\n",
      "Epoch 6 Training Completed: Train Avg. Loss: 0.2471\n",
      "Epoch 6 Validation Completed: Validation Avg. Loss: 0.2460\n",
      "This epoch took 9.71 seconds to complete\n",
      "Epoch 7 Training Completed: Train Avg. Loss: 0.2461\n",
      "Epoch 7 Validation Completed: Validation Avg. Loss: 0.2451\n",
      "This epoch took 9.62 seconds to complete\n",
      "Epoch 8 Training Completed: Train Avg. Loss: 0.2453\n",
      "Epoch 8 Validation Completed: Validation Avg. Loss: 0.2445\n",
      "This epoch took 9.94 seconds to complete\n",
      "Epoch 9 Training Completed: Train Avg. Loss: 0.2446\n",
      "Epoch 9 Validation Completed: Validation Avg. Loss: 0.2436\n",
      "This epoch took 10.25 seconds to complete\n",
      "Epoch 10 Training Completed: Train Avg. Loss: 0.2440\n",
      "Epoch 10 Validation Completed: Validation Avg. Loss: 0.2432\n",
      "This epoch took 9.61 seconds to complete\n",
      "Epoch 11 Training Completed: Train Avg. Loss: 0.2435\n",
      "Epoch 11 Validation Completed: Validation Avg. Loss: 0.2424\n",
      "This epoch took 9.65 seconds to complete\n",
      "Epoch 12 Training Completed: Train Avg. Loss: 0.2429\n",
      "Epoch 12 Validation Completed: Validation Avg. Loss: 0.2422\n",
      "This epoch took 8.33 seconds to complete\n",
      "Epoch 13 Training Completed: Train Avg. Loss: 0.2424\n",
      "Epoch 13 Validation Completed: Validation Avg. Loss: 0.2419\n",
      "This epoch took 7.43 seconds to complete\n",
      "Epoch 14 Training Completed: Train Avg. Loss: 0.2421\n",
      "Epoch 14 Validation Completed: Validation Avg. Loss: 0.2414\n",
      "This epoch took 7.60 seconds to complete\n",
      "Epoch 15 Training Completed: Train Avg. Loss: 0.2417\n",
      "Epoch 15 Validation Completed: Validation Avg. Loss: 0.2410\n",
      "This epoch took 7.55 seconds to complete\n",
      "Epoch 16 Training Completed: Train Avg. Loss: 0.2415\n",
      "Epoch 16 Validation Completed: Validation Avg. Loss: 0.2408\n",
      "This epoch took 7.57 seconds to complete\n",
      "Epoch 17 Training Completed: Train Avg. Loss: 0.2412\n",
      "Epoch 17 Validation Completed: Validation Avg. Loss: 0.2405\n",
      "This epoch took 7.51 seconds to complete\n",
      "Epoch 18 Training Completed: Train Avg. Loss: 0.2410\n",
      "Epoch 18 Validation Completed: Validation Avg. Loss: 0.2403\n",
      "This epoch took 7.51 seconds to complete\n",
      "Epoch 19 Training Completed: Train Avg. Loss: 0.2407\n",
      "Epoch 19 Validation Completed: Validation Avg. Loss: 0.2401\n",
      "This epoch took 7.62 seconds to complete\n",
      "Epoch 20 Training Completed: Train Avg. Loss: 0.2405\n",
      "Epoch 20 Validation Completed: Validation Avg. Loss: 0.2400\n",
      "This epoch took 7.65 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "#Training and validation\n",
    "for epoch in range(num_of_epochs):\n",
    "    start_time = time.time()\n",
    "    #Training\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    n_samples = 0\n",
    "    for iteration, (prev_img, next_img, expcted_img) in enumerate(train_loader):\n",
    "        prev_img = prev_img.to(device=device)\n",
    "        next_img = next_img.to(device=device)\n",
    "        expcted_img = expcted_img.to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(prev_img,next_img)\n",
    "\n",
    "        loss = 1 - criterion_ssim(output, expcted_img)\n",
    "\n",
    "        loss_value = loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss_value * prev_img.shape[0]\n",
    "        n_samples += prev_img.shape[0]\n",
    "    print(\"Epoch {} Training Completed: Train Avg. Loss: {:.4f}\".format(epoch+1, epoch_loss/n_samples))\n",
    "    \n",
    "    #Validation\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    n_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for prev_img, next_img, expcted_img in validation_loader:\n",
    "            prev_img, next_img = prev_img.to(device),next_img.to(device)\n",
    "            expcted_img = expcted_img.to(device)\n",
    "\n",
    "            output = model(prev_img, next_img)\n",
    "\n",
    "            loss = 1 - criterion_ssim(output, expcted_img)\n",
    "\n",
    "            total_loss += loss.item() * prev_img.shape[0]\n",
    "            n_samples += prev_img.shape[0]\n",
    "    print(\"Epoch {} Validation Completed: Validation Avg. Loss: {:.4f}\".format(epoch+1, total_loss/n_samples))\n",
    "    end_time = time.time() - start_time\n",
    "    print(\"This epoch took {:.2f} seconds to complete\".format(end_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
